---
title: Practical Machine Learning Project Report
author: "by CM"

---

## Introduction  
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  

In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise.  

## Loading Libraies  
```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
```
### Getting the Data
```{r}
setwd("/Users/cjmarchante/Desktop/My Data/Data Science Specialization/8 Practical Machine Learning/project/my project- Practical Machine Learning")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "../data/pml-training.csv"
testFile  <- "../data/pml-testing.csv"
if (!file.exists("../data")) {
  dir.create("../data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}
```  
### Reading the Data
We read the CVS files into the corresponding dataframes.  
```{r}
trainRawdata <- read.csv("../data/pml-training.csv")
testRawdata <- read.csv("../data/pml-testing.csv")
dim(trainRawdata)
dim(testRawdata)
```
The training data set contains 19622 observations and 160 variables, while the testing data set contains 20 observations and 160 variables. The "classe" variable in the training set is the outcome to predict. 
We explore the data seeing that there are N/A values and columns that are not useful for the analysis.

### Data cleansing

Removing N/A and non-useful variables.

First, we remove columns that contain NA missing values.
```{r}
trainRawdata <- trainRawdata[, colSums(is.na(trainRawdata)) == 0] 
testRawdata <- testRawdata[, colSums(is.na(testRawdata)) == 0] 

```  
Next, we remove the first seven columns that do add no information to the measurements.
```{r, cache = T}
classe <- trainRawdata$classe

trainRemove <- grepl("^X|timestamp|window", names(trainRawdata))
trainRawdata <- trainRawdata[, !trainRemove]
trainCd <- trainRawdata[, sapply(trainRawdata, is.numeric)]
trainCd$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRawdata))
testRawdata <- testRawdata[, !testRemove]
testCd <- testRawdata[, sapply(testRawdata, is.numeric)]


```

### Splitting Training data set
Then, we  split the cleaned training set into 70% real training and 30% for validation data set to conduct cross validation in the coming steps.  
```{r}
set.seed(12122) 
inTrain <- createDataPartition(trainCd$classe, p=0.70, list=FALSE)
trainData <- trainCd[inTrain, ]
testData <- trainCd[-inTrain, ]
```

## Data Modeling
We fit a predictive model using **Random Forest** algorithm since there are lot of of variables in order to select the important ones and because there is medium higer correlation between variables as we can see in appendix 1 correlation matrix plot.
We consider only 2-fold cross validation (default setting in trainControl function is 10) so we will save a little computing time.

```{r}
controlRf <- trainControl(method="cv", 2)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf)
modelRf
```
Then, we estimate the performance of the model on the validation data set.  
```{r, cache = T}
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
```
```{r, cache = T}
Accuracy <- postResample(predictRf, testData$classe)
Accuracy

```

We obtained a model with an accuracy of 99.1%.


## Predicting for Test Data Set
We now use random forests to predict the outcome variable classe for the testing set.  
```{r, cache = T}
result <- predict(modelRf, testCd)
result
```  

## Appendix: Figures
1. Correlation Matrix   
```{r, cache = T}
corrPlot <- cor(trainData[, -length(names(trainData))])
corrplot(corrPlot, method="color")
```
2. Decision Tree 
```{r, cache = T}
treeModel <- rpart(classe ~ ., data=trainData, method="class")
prp(treeModel) 
```